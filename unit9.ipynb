{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "unit9.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMU7wj2bwCeWQ2mLC1Gkb6v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ujin2021/ML_CrashCourse/blob/main/unit9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oi90f-l9eIaU"
      },
      "source": [
        "### 정규화(L₂정규화)\r\n",
        "\r\n",
        "![image](https://user-images.githubusercontent.com/53362054/103459288-94daf780-4d51-11eb-9db5-6b8bb175f8a0.png)\r\n",
        "<br>\r\n",
        "* 학습손실은 점차 감소, 검증손실은 증가\r\n",
        "* 이 곡선은 학습세트의 데이터에 대해 과적합\r\n",
        "* 복잡한 모델에 패널티를 부여하는 정규화 원칙 사용하여 과적합 방지\r\n",
        "* 원래는 min(손실(데이터|모델))이지만(경험적 위험 최소화)\r\n",
        "* min(손실(데이터|모델) + 복잡도(모델)) (구조적 위험 최소화)를 통해 모델의 복잡도도 최소화 한다\r\n",
        "* 모델 복잡도가 가중치에 대한 함수이다\r\n",
        "  * 높은 절대값을 사용하는 특성가중치는 낮은 절대값을 사용하는 특성가중치보다 더 복잡하다\r\n",
        "  * L₂정규화 : 모든 특성 가중치를 제곱한 값의 합계로서 정규화 항을 정의\r\n",
        "  * 0에 가까운 가중치는 모델 복잡도에 거의 영향을 미치지 않지만, 이상점 가중치는 큰 영향을 미친다\r\n",
        "\r\n",
        "* 예시\r\n",
        "![image](https://user-images.githubusercontent.com/53362054/103459365-424e0b00-4d52-11eb-9f4e-62e8e10682d6.png) <br>\r\n",
        "![image](https://user-images.githubusercontent.com/53362054/103459374-572a9e80-4d52-11eb-92fc-f670dd8f912a.png)\r\n",
        "<br>\r\n",
        "* 해당 가중치를 갖는 선형 모델의 L₂정규화 항은 26.915이며, 제일 큰 가중치인 w₃이 거의 모든 복잡도에 기여한다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgmhyP-1ghBF"
      },
      "source": [
        "#### 람다\r\n",
        "* 람다 라는 스칼라를 정규화 항의 값에 곱하여 정규화 항의 전반적인 영향을 조정한다\r\n",
        "* min(손실(데이터|모델) + (람다)복잡도(모델))\r\n",
        "* 람다를 곱함으로 써 가중치 값을 0으로 유도하고, 정규 분포를 사용하여 가중치 평균을 0으로 유도한다\r\n",
        "* 람다 값을 높이면 정규화 효과가 강화된다\r\n",
        "* 람다 값이 너무 높으면 모델은 단순해지지만 데이터가 과소적합해질 위험이 있다. 그렇게 되면 모델은 유용한예측을 수행할 만큼 충분한 학습이 이루어 지지 않을 수 있다\r\n",
        "* 람다값이 너무 낮으면 모델은 복잡해지고, 과적합될 수 있다. 모델이 학습데이터의 특수성을 너무 많이 학습하게되어 새로운 데이터로 일반화 하지 못한다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fckZL6N5hJ1I"
      },
      "source": [
        "* 복잡한 모델에 패널티를 주는 방법 이외에 조기 중단이라는 방법도 있다\r\n",
        "* 조기중단이란 모델이 완전히 수렴되기 전 학습을 끝내는 것이다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpZN3Bzbd-CO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}